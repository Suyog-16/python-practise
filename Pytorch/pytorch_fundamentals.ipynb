{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pytorch\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1+cu124'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the version of pytorch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "Tensors are builiding blocks or container which can house data in N dimensions.\n",
    "Tensors can be created using class torch.Tensor\n",
    "Note:\n",
    "1) scalars are zero rank(or dimension) tensor\n",
    "2) vectors are one rank(or dimesnion) tensor\n",
    "3) Matrices are 2 rank(or dimension) tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "#creating scalar\n",
    "scalar = torch.tensor(2)\n",
    "print(scalar.item())\n",
    "print(scalar.ndim)# dimension of tensor\n",
    "print(scalar.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3])\n",
      "1\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "#creating vectors\n",
    "vector = torch.tensor([2,3])\n",
    "print(vector)\n",
    "print(vector.ndim)\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating matrix\n",
    "matrix = torch.tensor([[2,3],[3,4]])\n",
    "matrix.ndim # 2\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a tensor\n",
    "TENSOR = torch.tensor([[[2,3,1]\n",
    "                        ,[3,4,3]]])\n",
    "TENSOR.ndim # 3\n",
    "TENSOR.shape # (1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets practise some more\n",
    "# TENSOR_1 = torch.tensor([[[2,3,4,5],\n",
    "#                           [3,4,5],\n",
    "#                           [3,4,5]]])\n",
    "# TENSOR_1.ndim # This will throw error as the elements are of different dimesnions\n",
    "\n",
    "TENSOR_2 = torch.tensor([[[2,3],\n",
    "                          [3,4],\n",
    "                          [9,8],\n",
    "                          [3,8]]])\n",
    "TENSOR_2.ndim # 3\n",
    "TENSOR_2.shape #(1,4,2)\n",
    "\n",
    "TENSOR_3 = torch.tensor([[[[2,3],\n",
    "                           [3,4],\n",
    "                           [5,6]],\n",
    "                           [[2,3],\n",
    "                            [4,5],\n",
    "                            [1,1]]]])\n",
    "TENSOR_3.ndim #4\n",
    "TENSOR_3.shape ## [1,2,3,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "Creating Random tensor with the method torch.rand() with size parameters.\n",
    "Lets create random tensors with above dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0996, 0.1792],\n",
      "        [0.3859, 0.3250]])\n",
      "tensor([[[[0.8024, 0.8551],\n",
      "          [0.6709, 0.0129],\n",
      "          [0.9996, 0.5144]],\n",
      "\n",
      "         [[0.8459, 0.1175],\n",
      "          [0.9421, 0.2515],\n",
      "          [0.4986, 0.4943]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0150, 0.6904, 0.0415],\n",
       "         [0.1192, 0.7050, 0.9442],\n",
       "         [0.8003, 0.4289, 0.5674],\n",
       "         ...,\n",
       "         [0.9030, 0.8946, 0.2433],\n",
       "         [0.1128, 0.9165, 0.0277],\n",
       "         [0.5469, 0.6940, 0.6750]],\n",
       "\n",
       "        [[0.6423, 0.2284, 0.9378],\n",
       "         [0.5158, 0.2379, 0.2677],\n",
       "         [0.2932, 0.5081, 0.1231],\n",
       "         ...,\n",
       "         [0.6051, 0.9254, 0.1196],\n",
       "         [0.4678, 0.6555, 0.4571],\n",
       "         [0.8275, 0.5739, 0.2814]],\n",
       "\n",
       "        [[0.9252, 0.4298, 0.8242],\n",
       "         [0.7110, 0.6437, 0.2238],\n",
       "         [0.7320, 0.6759, 0.5130],\n",
       "         ...,\n",
       "         [0.2449, 0.9922, 0.9406],\n",
       "         [0.9743, 0.0033, 0.9036],\n",
       "         [0.8470, 0.9124, 0.9759]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0754, 0.1630, 0.6968],\n",
       "         [0.7538, 0.3959, 0.2796],\n",
       "         [0.1434, 0.7641, 0.0442],\n",
       "         ...,\n",
       "         [0.2873, 0.4422, 0.2898],\n",
       "         [0.1383, 0.1386, 0.9115],\n",
       "         [0.8316, 0.6834, 0.7032]],\n",
       "\n",
       "        [[0.7664, 0.2565, 0.9344],\n",
       "         [0.6821, 0.3336, 0.7141],\n",
       "         [0.7570, 0.4980, 0.6635],\n",
       "         ...,\n",
       "         [0.7607, 0.9736, 0.5708],\n",
       "         [0.6403, 0.3569, 0.9914],\n",
       "         [0.4629, 0.0167, 0.1302]],\n",
       "\n",
       "        [[0.5015, 0.0863, 0.4839],\n",
       "         [0.3864, 0.3340, 0.1328],\n",
       "         [0.3347, 0.3314, 0.1939],\n",
       "         ...,\n",
       "         [0.5615, 0.1992, 0.2575],\n",
       "         [0.3193, 0.1003, 0.4262],\n",
       "         [0.2260, 0.3149, 0.5343]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating random tensor of size(2,2)\n",
    "random_tensor = torch.rand(size=(2,2))\n",
    "print(random_tensor)\n",
    "#creating tensor of size (1,2,3,2)\n",
    "random_tensor1 = torch.rand(size=(1,2,3,2))\n",
    "print(random_tensor1)\n",
    "\n",
    "#creating an tensor for common image shape (224,224,3)\n",
    "image_tensor = torch.rand(size = (224,224,3)) #(heigtht,width,colorchannels)\n",
    "image_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets create tensors of ones and zeros using torch.zeros and torch.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating zeros tensor\n",
    "zeros = torch.zeros(size=(1,2,3))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating ones tensor\n",
    "ones = torch.ones(size = (3,4,1))\n",
    "ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a range of tensor using torch.arange(start,end,steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten = torch.arange(0,10)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
       "        28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
       "        46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n",
       "        64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n",
       "        82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_to_hun = torch.arange(start=10,end=100,step=1)\n",
    "tens_to_hun\n",
    "# Note you cant create a range in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sometimes if you want a zero or one tensor with the shape of a already existing tensor that you can achieve it through torch.zeros_like(input = tensor_name) and torch.ones_like(input = tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a zeros_like tensor for the tensor above(tens_to_hun)\n",
    "zeros_tens_to_hun = torch.zeros_like(input = tens_to_hun)\n",
    "zeros_tens_to_hun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now same for the ones_like\n",
    "ones_like_tens_to_hun = torch.ones_like(tens_to_hun)\n",
    "ones_like_tens_to_hun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Datatype\n",
    "Default datatype in tensors is float32. Pytorch wants every tensor to be in a same format and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_tensor = torch.tensor([3.9,3.7,3.4],\n",
    "                              dtype=None,# default i.e float32\n",
    "                              device = None,#default to cpu\n",
    "                              requires_grad=False\n",
    "                              )\n",
    "default_tensor.shape,default_tensor.dtype,default_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor with float 16 datatype\n",
    "float_16_tensor = torch.tensor([2,3,4],\n",
    "                               dtype=torch.float16)\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common errors in Pytorch arises due to :\n",
    "1) shape of tensor\n",
    "2) datatype of tensor\n",
    "3) device where tensor is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manupilating tensors\n",
    "Some of the tensor operation are as follows\n",
    "1) Addition\n",
    "2) Subtractions\n",
    "3) Multiplication(element wise)\n",
    "4) Division\n",
    "5) Matrix Multiplication (MOST IMPORTANT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7, 8, 9]), torch.int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a tensor of values\n",
    "tensor = torch.tensor([2,3,4])\n",
    "tensor += 5\n",
    "tensor,tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([70., 80., 90.]), torch.float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets multiply all the elements with 10\n",
    "tensor *= 10\n",
    "tensor,tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7., 8., 9.]), torch.float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets divide it by 10\n",
    "tensor = tensor/10\n",
    "tensor,tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([70000, 80000, 90000]), torch.int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplying using torch.multiply\n",
    "tensor = torch.multiply(tensor,10)\n",
    "tensor,tensor.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "In pytorch we use the method torch.matmul() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor = torch.tensor([1,2,3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(Tensor,Tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix multiplication of two tensors A and B\n",
    "tensor_A = torch.tensor([[2,3,4,5],\n",
    "                         [2,1,6,7]])# size of(2,4)\n",
    "tensor_B = torch.tensor([[2,3,4,5],\n",
    "                         [3,2,1,5]])# size of (2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the inner dimensions dont match. We can only opearte matrix multiplication after obtaining transpose of tensor_B making their inner dimension match(4=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3, 4, 5],\n",
      "        [2, 1, 6, 7]])\n",
      "tensor([[2, 3, 4, 5],\n",
      "        [3, 2, 1, 5]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [3, 2],\n",
       "        [4, 1],\n",
       "        [5, 5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B = tensor_B.T # transpose operation\n",
    "tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3, 4, 5],\n",
      "        [2, 1, 6, 7]])\n",
      "tensor([[2, 3],\n",
      "        [3, 2],\n",
      "        [4, 1],\n",
      "        [5, 5]])\n"
     ]
    }
   ],
   "source": [
    "# tensors after tranpose\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[54, 41],\n",
       "        [66, 49]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "mat_mut = torch.matmul(tensor_A,tensor_B)\n",
    "mat_mut # size is (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for the datatype\n",
    "mat_mut.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when doing torch.matmul it preserves the initial data type and doesnt convert into the default datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[54, 41],\n",
       "         [66, 49]]),\n",
       " torch.Size([2, 2]),\n",
       " torch.int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using torch.mm() method\n",
    "mm = torch.mm(tensor_A,tensor_B)\n",
    "mm,mm.shape,mm.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the min,max,mean,sum etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a tensor \n",
    "x = torch.arange(0,100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0\n",
      "Max: 90\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min: {x.min()}\")\n",
    "print(f\"Max: {x.max()}\")\n",
    "# print(f\"Mean: {x.mean()}\") # this will throw error because it requires tensors to be a float32 dtype\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 45.0\n"
     ]
    }
   ],
   "source": [
    "x = x.type(torch.float32) # changing datatype from int64 to float32\n",
    "print(f\"Mean: {x.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower the datatype the faster the computation. Eg: float32 is faster computation than float64 or int64 but less accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping,stacking,squezzing and unsqueezing\n",
    "These are techniques that aid in manupulating tensors with shape mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), torch.int64, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets create a tensor \n",
    "y = torch.arange(0,100,10)\n",
    "y.shape,y.dtype,y.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape\n",
    "torch.reshape() returns a tensor wiht the same data and number of elements as input, but with the specified shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped= y.reshape(1,10) # 1 is the specified shape\n",
    "y_reshaped.ndim# 2 because we have added 1 extra dimesion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.reshape(y,(1,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also change the view with torch.view()\n",
    "z = y.view(1,10)\n",
    "z,z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember though, changing the view of a tensor with torch.view() really only creates a new view of the same tensor.\n",
    "\n",
    "So changing the view changes the original tensor too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10, 10, 20, 30, 40, 50, 60, 70, 80, 90]]),\n",
       " tensor([10, 10, 20, 30, 40, 50, 60, 70, 80, 90]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:,0] = 10\n",
    "z,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "stacks one tensor over the other accoriding to the parameters provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
       "         [10, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
       "         [10, 10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
       "         [10, 10, 20, 30, 40, 50, 60, 70, 80, 90]]),\n",
       " tensor([[10, 10, 10, 10],\n",
       "         [10, 10, 10, 10],\n",
       "         [20, 20, 20, 20],\n",
       "         [30, 30, 30, 30],\n",
       "         [40, 40, 40, 40],\n",
       "         [50, 50, 50, 50],\n",
       "         [60, 60, 60, 60],\n",
       "         [70, 70, 70, 70],\n",
       "         [80, 80, 80, 80],\n",
       "         [90, 90, 90, 90]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use of torch.stack()\n",
    "y_stacked = torch.stack([y,y,y,y],dim=0) # Observe\n",
    "y_stacked1 = torch.stack([y,y,y,y],dim=1)# Observe\n",
    "y_stacked,y_stacked1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Squeeze\n",
    "It essentially removes all single dimensions from a tensor. YOu can only apply this to dimensions higher than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]]), torch.Size([1, 10]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we take a tensor of 2 dimensions\n",
    "y_reshaped,y_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]]) \n",
      "Previous tensor size: torch.Size([1, 10]) \n",
      "Present tensor: tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]) \n",
      "Present tensor size: torch.Size([10]) \n"
     ]
    }
   ],
   "source": [
    "# lets squeeze the tensor y_reshaped\n",
    "print(f\"Previous tensor: {y_reshaped} \")\n",
    "print(f\"Previous tensor size: {y_reshaped.shape} \")\n",
    "# after squeezing\n",
    "squeezed_y = y_reshaped.squeeze()\n",
    "print(f\"Present tensor: {squeezed_y} \")\n",
    "print(f\"Present tensor size: {squeezed_y.shape} \")# 1D is removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsqueeze \n",
    "The reverse action of squeeze is unsqueeze. It adds a dimension value of 1 at a specific index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous squeezed tensor: tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Previous squeezed tensor size: torch.Size([10])\n",
      "Present unsqueezed tensor: tensor([[ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]])\n",
      "Present unsqueezed tensor shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous squeezed tensor: {squeezed_y}\")\n",
    "print(f\"Previous squeezed tensor size: {squeezed_y.shape}\")\n",
    "# lets perform unsqueezing\n",
    "y_unsquezzed = squeezed_y.unsqueeze(dim = 0) # try different dimensions\n",
    "print(f\"Present unsqueezed tensor: {y_unsquezzed}\")\n",
    "print(f\"Present unsqueezed tensor shape: {y_unsquezzed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
